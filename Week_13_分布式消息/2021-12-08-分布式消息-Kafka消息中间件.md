# 分布式消息：Kafka消息中间件

[toc]

## 一、什么是Kafka

Kafka 是一种分布式的，基于发布 / 订阅的消息系统

> 所有消息都是基于Topic。

kafka被设计的目标：

1. 持久化和性能；

    不管持久化多少数据，都不会影响其性能。但这不是绝对的。

2. 高吞吐率

   顺序写，无论是写还是读性能非常高。

3. 顺序

   保证消息传递到消费者那里，能够顺序传输。有序就可以保证业务上的有序。

4. 支持离线和实现数据处理

5. 支持水平扩展（与partition相关）

## 二、kafka的基本概念

- broker：代理、经纪人

  Kafka 集群包含一个或多个服务器，这种服务器被称为 broker。

- Topic：每条发布到 Kafka 集群的消息都有一个类别，这个类别被称为 Topic

  物理上不同 Topic 的消息分开存储，逻辑上一个 Topic 的消息虽然保存于一个或 多个 broker 上，但用户只需指定消息的 Topic 即可生产或消费数据而不必关心数 据存于何处

- partition：Partition 是物理上的概念，每个 Topic 包含一个或多个 Partition

- Producer：负责发布消息到 Kafka broker

- Consumer：消息消费者，向 Kafka broker 读取消息的客户端

- Consumer Group：每个 Consumer 属于一个特定的 Consumer Group

  > 可为每个 Consumer 指定 group name，若不指定 group name 则属于默认的 group

  每个消费者组拿到的都是全量消息，一个组内所有Consuner拿到的消息总和为全量消息，也就是一个组内多个Consumer协同处理一个topic消息。

## 三、kafka消息处理

### 3.1 单机模式和集群模式

- 生产者把消息发送到某个具体的topic partition上（partition默认只有一个）；

- 多个partition意味着可以并发操作；
- 集群的时候，通过zookeeper把机器的状态信息记录在上面；

kafka单机信息处理：

![单机kafka信息处理](./photos/001单机kafka信息处理.png)

集群kafka信息处理：

![集群kafka信息处理](./photos/002集群kafka信息处理.png)

### 3.2 Topic 和 partition

多Partition支持水平扩展和并行处理，顺序写入提升吞吐性能。

Topic 是逻辑概念，Partition是物理概念，在创建topic的时候可以指定partition的数目：

（1）每个partition都相当于一个子的队列；

（2）我们发送一条信息到底写到哪个partition，这是在客户端完成的，跟borker没关系；

（3）如果我们想要拿到topic上面所有的数据，我们就需要订阅topic对英的所有partition；

（4）单个机器上不建议有大量partition，也不建议有大量topic，因为一个partition对应一个数据文件；

单个机器上，数据文件太多，意味着随机IO读写。建议单机上topic+partition在十个以内。加磁盘可以缓解这个问题。

单机partition越多，随机读写就越多。

（5）单个partition是有序的，多个partition就没有顺序了。

- topic  可以理解成数据库的表（table）；
- message可以理解成数据库的行（row）；
- partition可以理解成 sharding/partition；

### 3.3 Partition和Replica

我们在创建topic时，除了可以指定partition，还可以指定副本个数的参数。

### 3.4 topic特性

（1）通过partition提升性能；

topic创建之后，还可以人为改变partiton和副本数，但这样会导致性能抖动。

（2）通过顺序写入达到高吞吐；

（3）通过多副本，增加容错性；

### 3.5 真实案例：kafka性能问题解决方案

随着业务发展，在kafka上面建立几万个partition，优化方案如下：

（1）把一个topic下面20多个partition合成一个，通过加tag来区分不同消息的逻辑处理

此时partition减少了一个数量级，但是还有一千多个，还需要继续优化。

（2）把磁盘都换成SSD（成本一下子都上去了）；

（3）降低当前kafka集群中热数据的数量：

- 一方面把kafka中一部分数据放到普通磁盘中，另一方面将kafka日志过期策略从原来一个月改为一个星期；
- 将特别热的数据过期策略改为2～3天，降低kafka本身在磁盘中的容量



## 四、单机kafka

### 4.1 配置

修改`config/server.properties`:

```
打开 listeners=PLAINTEXT://localhost:9092
```

### 4.2 启动zookeeper和kafka服务

```
-- 启动zookeeper
nohup bin/zookeeper-server-start.sh config/zookeeper.properties 1>zookeeper.out 2>&1 &
-- 启动kafka
nohup bin/kafka-server-start.sh config/server.properties 1>kafka.out 2>&1 &

-- 通过命令行进入zookeeper
./bin/zookeeper-shell.sh localhost:2181
```

### 4.3 基本的操作命令

```
-- 查看topic列表
bin/kafka-topics.sh --zookeeper localhost:2181 --list 
-- 创建topic名称为 testk 
bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic testk --partitions 4 -replication-factor 1 
-- 查看topic的描述
bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic testk 
-- 在命令行 开启一个consumer
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning -topic testk 
-- 在命令行 开启一个producer
bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic testk

-- 简单的性能测试
-- 测试生成者的性能
bin/kafka-producer-perf-test.sh --topic testk --num-records 100000 --record-size 1000 --throughput 2000 --producer-props bootstrap.servers=localhost:9092
-- 测试消费者的性能
bin/kafka-consumer-perf-test.sh --bootstrap-server localhost:9092 --topic testk -fetch-size 1048576 --messages 100000 --threads 1
```





## 五、kafka集群

 模拟在单台服务器上，启动三节点的kafka集群：

### 5.1 配置

`kafka/` 文件夹下

```
cp config/server.properties kafka9001.properties
```

```
-rw-r--r--    1 lifei  staff  29975 12 16  2020 LICENSE
-rw-r--r--    1 lifei  staff    337 12 16  2020 NOTICE
drwxr-xr-x   36 lifei  staff   1152 12 16  2020 bin
drwxr-xr-x   17 lifei  staff    544 12 16  2020 config
-rw-r--r--    1 lifei  staff   7006 12 11 13:15 kafka9001.properties
-rw-r--r--    1 lifei  staff   7006 12 11 13:16 kafka9002.properties
-rw-r--r--    1 lifei  staff   7006 12 11 13:17 kafka9003.properties
drwxr-xr-x  103 lifei  staff   3296 12 16  2020 libs
drwxr-xr-x    3 lifei  staff     96 12 16  2020 site-docs
```



```
$ cat kafka9001.properties | grep -v '^$' | grep -v '^#'
broker.id=1   # 三个文件分别改为 1、2、3
listeners=PLAINTEXT://localhost:9001   # 三个文件分别改为 9001、9002、9003
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.dirs=/tmp/kafka/kafka-logs1    # 三个文件分别改为 1、2、3
num.partitions=1
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
log.retention.hours=168
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
zookeeper.connect=localhost:2181
zookeeper.connection.timeout.ms=18000
group.initial.rebalance.delay.ms=0
delete.topic.enable=true
message.max.bytes=5000000
replica.fetch.max.bytes=5000000
broker.list=localhost:9001,localhost:9002,localhost:9003
```



### 5.2 启动zookeeper和kafka

注意搭建kafka集群的时候，需要到zookeeper上，把之前zookeeper清空(否则启动后数据无法传递)：

```
-- 通过命令行进入zookeeper
./bin/zookeeper-shell.sh localhost:2181
-- 第一次执行 ls 命令的效果
ls /
[zookeeper]
```

启动zookeeper和kafka:

```
-- 启动 zookeeper
nohup bin/zookeeper-server-start.sh config/zookeeper.properties 1>zookeeper_nohup.out 2>&1 &
-- 启动 kafka 集群
nohup ./bin/kafka-server-start.sh ./kafka9001.properties 1>kafka9001.log 2>&1 &
nohup ./bin/kafka-server-start.sh ./kafka9002.properties 1>kafka9002.log 2>&1 &
nohup ./bin/kafka-server-start.sh ./kafka9003.properties 1>kafka9003.log 2>&1 &
```

###  5.3 基本的操作命令

```
-- 通过命令行进入zookeeper
./bin/zookeeper-shell.sh localhost:2181
-- 第一次执行 ls 命令的效果
ls /
[zookeeper]

-- 查看topic列表
./bin/kafka-topics.sh --zookeeper localhost:2181 --list

-- 创建一个带有两个副本的topic
./bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic test32 --partitions 3 --replication-factor 2

-- 查看topic描述
./bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test32

-- 启动一个消费者
./bin/kafka-console-consumer.sh --bootstrap-server localhost:9001,localhost:9002,localhost:9003  --from-beginning --topic test32


-- 启动一个生产者
./bin/kafka-console-producer.sh --bootstrap-server localhost:9001,localhost:9002,localhost:9003 --topic test32

-- 简单的生产者测试
bin/kafka-producer-perf-test.sh --topic test32 --num-records 100000 --record-size 1000 --throughput 2000 --producer-props bootstrap.servers=localhost:9002

-- 简单的消费者测试
bin/kafka-consumer-perf-test.sh --bootstrap-server localhost:9002 --topic test32 -fetch-size 1048576 --messages 100000 --threads 1

```



查看带有两个副本的topic描述：

```
$ ./bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test32
Topic: test32	PartitionCount: 3	ReplicationFactor: 2	Configs:
	Topic: test32	Partition: 0	Leader: 1	Replicas: 1,2	Isr: 1,2
	Topic: test32	Partition: 1	Leader: 2	Replicas: 2,3	Isr: 2,3
	Topic: test32	Partition: 2	Leader: 3	Replicas: 3,1	Isr: 3,1
```



## 六、简单的生产者和消费者Java程序

开发一个[极简的Java程序来测试kafka集群](https://gitee.com/lf-ren/JavaRebuild/tree/main/projects/kafka-demo/src/main/java/com/hef/kafkademo/server)：

### 6.1 引入Maven依赖

```
		<dependency>
			<groupId>org.apache.kafka</groupId>
			<artifactId>kafka_2.13</artifactId>
			<version>${kafka.version}</version>
		</dependency>
		<dependency>
			<groupId>org.apache.kafka</groupId>
			<artifactId>kafka-clients</artifactId>
			<version>${kafka.version}</version>
		</dependency>

		<dependency>
			<groupId>com.alibaba</groupId>
			<artifactId>fastjson</artifactId>
			<version>${fastjson.version}</version>
		</dependency>
```

### 6.2 简单的生产者程序

```java
    public static void main(String[] args) {
        MySimpleKafkaProducer producerMain = new MySimpleKafkaProducer();
        producerMain.producerSend();
    }

    public void producerSend() {
        Properties props = new Properties();
        props.setProperty("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.setProperty("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.setProperty("bootstrap.servers", "localhost:9001,localhost:9002,localhost:9003");
        String topic = "test32";

        KafkaProducer<String, String> producer = new KafkaProducer<>(props);
        // 发送消息
        for (int i = 0; i < 10; i++) {
            Order order = new Order();
            order.setAmount(new BigDecimal(1000+i));
            order.setId(i);
            order.setType(System.currentTimeMillis());
            String value = JSON.toJSONString(order);
            ProducerRecord<String, String> record = new ProducerRecord<>(topic, value);
            producer.send(record);
        }
        producer.close();
    }
```

### 6.3 简单的消费者程序

```java
    public static void main(String[] args) {
        MySimpleKafkaConsumer consumer = new MySimpleKafkaConsumer();
        consumer.consumerPoll();
    }


    public void consumerPoll() {
        Properties props = new Properties();
        props.setProperty("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.setProperty("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.setProperty("bootstrap.servers", "localhost:9001,localhost:9002,localhost:9003");
        // kafka group id 的配置
        props.setProperty("group.id", "group1");

        String topic = "test32";
        //  构建一个Consumer
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
        consumer.subscribe(Arrays.asList(topic));
        while (true) {
            ConsumerRecords<String, String> poll = consumer.poll(Duration.ofMillis(1000));
            poll.forEach(item->{
                ConsumerRecord<String, String> record = (ConsumerRecord) item;
                Order order = JSON.parseObject(record.value(), Order.class);
                System.out.println(order);
            });
            try {
                Thread.sleep(1000 * 10);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }
```

