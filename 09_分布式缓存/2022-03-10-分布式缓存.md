# 分布式缓存

[toc]

## 一、缓存

从为什么有缓存说起：从数据的使用说起。

两种常见的缓存：本地缓存、远程缓存。

再到常见的缓存策略，随后讲Redis会详细再讲缓存策略。

最后一个话题是（面试经常会问）——缓存世界的三大难题：缓存的穿透、缓存的击穿、缓存的雪崩。

学会背后的东西：技术在变，但背后的思想和方法永远不会变。

## 二、从数据的使用说起

### 2.1 我们把数据的使用频率和方式分个类

我们的业务系统越来越复杂，数据量越来越大，这样我们就可以对我们的业务数据进行 不同程序的分类，之前提到过，我们通过使用频率可以把数据分为：热数据、冷数据、温数据、冰数据。

#### （1）通过使用频率，我们还可以采用有一点点差异的方式进行分类：

- 静态数据：类似于字典表，长期不会变。

  比如性别数据。

- 准静态数据：变化频率很低

  比如：部门结构设置，全国行政区划数据（平均一年变一次）等

- 中间状态数据：一些计算的可复用的中间数据。一般不是原始数据，通过基础数据计算出来的中间状态的结果

  我们的流水数据是原始数据，我们可以根据流水数据计算出一个大的店铺的某个品类交易了多少钱。

  甚至我们可以说是，一个业务方法调用后返回的结构。这样的数据是中间状态数据。

  一般情况下，丢了无所谓，因为可以重新计算出来。但有时候计算的成本比较大。

  举例，变量副本：前面讲的JVM中的变量，每个线程都有其副本，它也是一个中间数据。

  举例，配置中心：配置中心可以配置一个本地的缓存文件夹，这样就可以放一些缓存的文件，把从配置中心拉取到的配置在本地缓存一份。如果配置中心宕机了，可以先用本地的。

- 变化中的动态数据（本文中不具体讲）

#### （2）这些需要缓存的数据特点：

- 热数据：虽然变动少，但它们是热数据，使用频率高。

  比如字典表，几乎所有的业务都在使用它们。

- 读写比大："读（n）/写（1）"非常大。读的频率>>写的频率

这些数据就特别适合做缓存。

#### （3）什么是缓存？

从广义上来讲，为了**加速**数据处理（降低数据库的压力）,让业务更快访问的**临时存放冗余数据**，都是缓存。

> 缓存本质上相当于原始数据的某种快照，如果跟原始数据一致的快照，那他就是对等快照。如果是中间状态，都是它加工映射过的快照。

狭义上，现在我们一般在分布式系统里把缓存到内存的数据叫内存缓存，有时候我们简称它为缓存。

> 放到内存中，加速访问，不走网络IO，磁盘IO，这些IO等慢操作，直接从内存里拿。

再狭义些，有些人把缓存称为Redis。

### 2.2  缓存无处不在

#### （1） 常见的缓存场景

缓存比我们平时在Java分布式系统下的语义要大得多：

场景一：

比如：内存本身可以看作是CPU和磁盘之间的缓存。因为CPU太快了，磁盘太慢了，内存的速度处于CPU和磁盘之间。

当CPU全速跑的时候，内存也会跟不上，这个时候就出现了CPU的缓存：L1&L2 cache。

场景二：

在网络处理、数据库引擎中有各种Buffer，这些Buffer我们称之为缓冲区，这些缓冲区就是用来放数据的，也是缓存。

场景三：

甚至在更早的时候，GUI画界面中有一个Double Buffer（双缓存），比如要画一个图，这个图需要用到10万个点，如果每画一个点就渲染一次，就会把页面卡死。优化的方案是：在内存区域，我们每1000次把点连起来。

场景四：

包括三大前端框架，用到虚拟DOM。

#### （2） 缓存的本质

**系统各级处理速度不匹配，导致利用空间换时间。**

系统里多个不同处理节点，这些处理节点处理速度是不匹配的，比如CPU和磁盘，CPU和内存，CPU的计算和实际屏幕的渲染等，这种相互之间速度是不匹配的。

为了加速这种处理，我们采用“空间换时间”的办法，把数据缓存一下。

因此，缓存是**提升系统性能**的一个简单有效的办法。

### 2.3 缓存的加载时机

通常来说，有两种缓存加载时机：

#### （1）启动时的全量缓存加载

全局有效，使用简单。

比如：Shardingsphere-jdbc、Shardingsphere-proxy启动的时候会把我们配置的多个数据源的元数据（多个数据库的表、表的列、索引）加载进来。

metadata-check的参数可以把这个加载关掉，会减少一部分的元数据的加载。

#### （2）懒加载

懒加载分为两种：

一种是：**同步使用加载**（最常见）

调用业务方法的时候，先去缓存里看一下，缓存里有就直接返回。没有的话，就去数据库里读，然后做业务操作，计算完之后把元数据和结果数据放到内存的某个地方，然后返回给调用方。

Shardingsphere 默认会缓存1024个SQL，这样就能减少对SQL的解析。

注意：Shardingsphere会根据不同的SQL作为key，匹配缓存。所以比较推荐使用占位符来拼接SQL，而不是动态拼接SQL。用占位符的方式，这个SQL就和参数没有关系，和SQL没有关系，意味着多次执行，尽管每次传的参数不一样，也没关系，SQL只需解析一次，以后不需要解析。

一种是：**延迟异步加载**

很多时候，我们不希望我们都每次调用：如果没有命中缓存，我们就去读数据库，或者中间经过一步非常复杂的操作。这样的话很慢，我的系统和我的线程都在这里卡死了。特别是我们的系统对一致性要求不那么高的情况下。或者我们调用特别频繁。

这个时候可以采取两种策略：

从缓存中获取数据，不管是否为空直接返回：

策略一（异步）：同时发布一个异步的请求线程，让其在后台慢慢加载缓存的数据。这样下次请求访问，就能命中了。

策略二（解耦）：（每次连异步线程都没有了）直接把缓存当作这块业务查询的数据库用，不发起线程。同时用额外的一套机制来维护我的缓存。这块机制对使用方来说是透明看得见的（不如：系统启动的时候，就把全量数据加载到缓存里。然后每次修改数据的操作都拦截掉，把涉及的数据更新到缓存里）。

### 2.4 缓存的有效性和数据同步

缓存的一致性和有效性。

#### （1）变动频率大、一致性要求高的数据，不太适合用缓存

变化大就意味着原始数据（数据库这边）和缓存数据一直有差异，这个时候数据来回同步的成本就比较高了。

一致性要求高，意味着只有使用**原始数据**，甚至加了**事务**，才是保险的。

> 一致性要求高，我们就要考虑每个线程不能使用一致性的副本。最好读主从读数据，而且加上同步的锁，才是保险的。这个时候也没办法用缓存。

#### （2） 如何评价缓存的有效性？

如果评价缓存用的对不对，有两个指标（有些人容易把这两个指标搞混，但这两者的差异非常大）：

**读写比**（N:1）：对数据的写操作导致数据变动，意味着维护成本。

读写比高，就意味着相关的这一批数据，它们改动的频率远远比读取的频率小。那么我们用缓存维护的成本就低（做中间频繁同步的频率就比较低）。一般我们要求这个比率为10:1以上。

这个与我们的数据量和频率有关。我们要求在一般的物理机上数据库的TPS在3000～5000，可以按照这个估计我们的QPS

**命中率**（也要高，90%以上）：命中缓存意味着缓存数据被使用，意味着有价值。

如果数据没有被命中，就是占地方。

缓存虽然有好处，但也有问题。

计算机只存在两个难题：失效和命名。

**对与数据一致性、性能、成本的综合衡量，是引入缓存的必须指标。**

到底要不要引入缓存，怎么引入缓存，哪些数据放入缓存，都需要我们做一些分析调用，最后做一个设计方案的。

### 2.5 缓存使用不当导致的问题

#### （1）系统预热导致系统启动比较慢

试想一下，一个系统启动需要预热半个小时。导致系统不能做到快速应对故障宕机等问题。

对现在来说，我们对系统的性能和稳定性要求这么高。假如，我们的系统宕机了，需要我们立刻拉起新的系统顶上。这个时候你给所有人说，需要半小时，大家可能会崩溃。

所以，我们现在对服务的业务系统，特别是做了微服务化以后，我们上容器化，上K8s Docker，有一个强的要求（包括我们在环境工程和系统稳定性建设里）——所有的系统都应该启动非常快。比如在一分钟或20秒内把单个系统的节点拉起来。这样的话，我们的系统崩溃了，我们找到前一个可用的版本，不管是拉取镜像还是把原来的版本拉起来，都可以快速恢复我们的业务，或降低业务恢复的时间。

#### （2）系统内存资源耗尽

只加入数据，不清理旧数据。旧数据处理不及时，或者不能有效识别无用数据。

跟我们的系统GC一摸一样。容量有限，不管是我们的缓存数据放在JVM内部做本地缓存，还是单独有一台机器用来做缓存。它的内存都是有限的。假如我们的数据使用不当，不断的往里面丢数据，这就跟GC一样，最后发生OOM（Out of Memory），系统就崩了。











