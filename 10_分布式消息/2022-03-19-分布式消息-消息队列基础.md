# 分布式消息：消息队列基础

[toc]

## 一、概要

本次学习主要涉及两大部分：

第一部分：消息队列是怎么来的，是怎么会事。

- 从系统的通信方式入手；
- 讲到怎么有消息队列；
- 消息队列相关的模式和相关协议；（重点）

第二部分：最常见的消息中间件：ActiveMQ

- 简单讲一些，因为新项目用得不多了；
- 实际的看一下代码，运行一个activeMQ的实例；

## 二、系统间的通信方式

### 2.1 系统间通信方式

我们知道两个进程，相互之间想传递数据，有很多的方式，比如：

- 基于文件

- 基于共享内存

  在同一台机器上，有一块共享内存，这两个进程都可以读取这一块共享内存

- 基于（一些）IPC（的通道）

  **进程间通信**（**IPC**，*Inter-Process Communication*），指至少两个[进程](https://zh.wikipedia.org/wiki/进程)或[线程](https://zh.wikipedia.org/wiki/线程)间传送数据或信号的一些技术或方法。

  这些进程可以运行在同一计算机上或网络连接的不同计算机上。

  主要的IPC方法：

  | 方法                                                         | 提供方（操作系统或其他环境）                                 |
  | ------------------------------------------------------------ | ------------------------------------------------------------ |
  | [文件](https://zh.wikipedia.org/wiki/檔案)                   | 多数操作系统                                                 |
  | [信号](https://zh.wikipedia.org/wiki/信号_(计算机科学))      | 多数操作系统                                                 |
  | [Berkeley套接字](https://zh.wikipedia.org/wiki/Berkeley套接字) | 多数操作系统                                                 |
  | [消息队列](https://zh.wikipedia.org/wiki/消息队列)           | 多数操作系统                                                 |
  | [管道](https://zh.wikipedia.org/wiki/管道_(Unix))            | 所有的[POSIX 系统](https://zh.wikipedia.org/wiki/POSIX), Windows. |
  | [命名管道](https://zh.wikipedia.org/wiki/命名管道)           | 所有的POSIX系统, Windows.                                    |
  | [信号量](https://zh.wikipedia.org/wiki/信号量)               | 所有的POSIX系统, Windows.                                    |
  | [共享内存](https://zh.wikipedia.org/wiki/共享内存)           | 所有的POSIX系统, Windows.                                    |
  | [消息传递](https://zh.wikipedia.org/wiki/訊息傳遞_(軟體))    | 用于[MPI](https://zh.wikipedia.org/wiki/MPI)规范，[Java RMI](https://zh.wikipedia.org/wiki/Java_RMI)，[CORBA](https://zh.wikipedia.org/wiki/CORBA)，[MSMQ](https://zh.wikipedia.org/w/index.php?title=MSMQ&action=edit&redlink=1)，[MailSlot](https://zh.wikipedia.org/w/index.php?title=MailSlot&action=edit&redlink=1)以及其他. |
  | [内存映射文件](https://zh.wikipedia.org/wiki/内存映射文件)   | 所有的POSIX系统, Windows.                                    |

- 基于Socket

  如果跨了机器，不在一个系统上，我们两个不同的进程，分别在不同的机器上。

  这个时候我们可以：

  方法一，走网络的共享文件，或者定期把A机器上文件，定期拷贝到B机器上（基于共享的，复制文件的方式）

  基于文件的很不好。

  > 案例，在某行内部，由于两套系统是物理隔离的，一个系统想要另一个系统的数据，通过人工使用U盘用文件拷贝的方式实现。这样不可控的因素就比较多。

  方法二：基于网络

  想早期的C-S方式，将一台机器作为客户端，另一台机器作为服务端，两台机器进行通信就可以了。

- 基于数据库

  一个系统往数据库写数据，另一个系统把数据读出来。反过来，两台机器都可以对数据库进行写入和读取，这样就能通过数据库进行系统间的通信。

- 基于缓存

  甚至可以基于什么，把缓存当作一个简单的内存数据，通过缓存也是可以的。

- 基于RPC

### 2.2 各通信方式的优点和缺点

每个模式，有自己的优点，也有自己的缺点。

- 文件：明显不方便，不及时

  优点：最大的优点是，基于文件操作的API，几乎所有的环境都支持的。如果对实时性要求不高，从读文件开始，这就是一种简单实用的方式。甚至当我们的文件特别特别大（比如100G），都没关系。只要我们能同步，能拷贝过去，到另外一个系统上，都能用。

- Socket：使用麻烦，多数情况下不如RPC。

  Socket默认也是同步的。

  优点：通过网路，很高效，效率非常高。

  缺点：比较麻烦，比如我们基于TCP的通信，需要两边建立监听，自己维护连接，定义两遍传输的报文，还有报文的传输、序列化等。

- 数据库：不实时，

  数据库这种方式是异步的。

  优点：是一个好一点的办法，数据库本身对数据的持久化做得比较好。

  > 这次的作业里就有提这会儿事。

  在工作中的很多场景下，很多的系统里，很多研发团队里，真的见到过大家，在拿数据库模拟消息队列。

  > 比如，数据库里有一个下单表，把订单写进来，一条条新的订单，状态都是没有处理的，另外一个系统，我们定时的一百毫秒一次，从这张表中去捞取，所有状态为未处理（比如 0 是未处理，1是已处理）。拿所有状态为0的数据，处理完之后，把状态改过去，那么这条数据就是处理过的。
  >
  > 这个时候，相当于我们拿数据库，在模拟一个消息队列。本来是接收系统的业务A和处理系统的业务B。他两个之间要做一个通信的交互，现在我们没有用消息队列，我们用数据库。如果我们把每条信息，看作是一个消息的话，相当于A在不停的往里面写消息，B在获取消息，然后处理和消费它。最后处理完的，状态为完成或结束的订单，状态为1的，就是我们处理好的。
  >
  > 这种非常常见，在很多系统里都见到了。

  这种方式，会有一个轮询的时间间隔，数据库本身发生了变化，不会通知我们的业务系统（就是我们的业务系统是数据库的），数据库不会给我们发消息，发通知，只能我们自己去拿。所以我们就必须用轮询，常见的轮询方式有：定义100百毫。那么就意味着，所有订单，从下单到对订单的处理。光这一个窗口就需要延迟100毫秒以上，再加上业务自己处理的时间。所以这块非常的没有保障。假如我们处理一段业务超时了怎么办，下个时间窗口又来了，是推后延迟了，还是不管，就接着处理后面的。这样可能导致，我前面一批没有处理完，后面一批又被加载进来处理了。后面的可能先处理，后面的可能后处理。

  在一些需要强实时性，强保证顺序的业务场景里，这种方式非常的不合适。可以做，但是需要加很多的，比如异常处理策略、重试。怎么控制下一个时间窗口，比如这个时间窗口没有处理完，把它往后移动。每次把未处理的订单全量的加载进来，还是我只处理一批。

  全量处理有一个很大的问题，假如，这一瞬间，流量非常大，一下子来了一万条记录，我这100毫秒内，处理一万条记录是不实现的。那我怎么办，假如我只取一千条记录，能处理得完，还剩九千条数据，就被卡在另外一个个时间窗口里了。也就是说，我这一万条，一秒钟进来的，可能最终我需要经过10个100毫秒，也就是1秒的延迟，才能把它们处理完。

  所以，用这种方式，有很多的限制和制约因素。实时性不太好。很多策略需要我们手工的去做。

  我们学了MQ之后，我们会发现，把这些策略全部加上，其实相当于我们用数据库的方式，自己手写了一个所谓的消息队列。

- RPC：调用关系复杂，同步处理，压力大的时候无法缓存

  优点：就像下面这张图一样，很简单，很直接。这种方式中间没有额外的消耗性的点。所以实时性比较好，整体的性能损耗也比较低。

  缺点：问题在于，第一，会使系统与系统之间的关系特别复杂（依赖关系太复杂了）。第二，因为它的实时性非常高，也就是说，A去调E的话，这个时候E不在线（比如，和E提供相同服务的机器都不在线），那么现在A就永远失败。系统之间的传递信息就不成立（这也是个问题）。第三个问题，压力大的时候，无法做缓冲，因为所有的压力都是实时传送到服务端这头的。比如1万条1秒钟，全都压过来，它就得处理。假如它这一瞬间，处理不了，可能就把它压崩了。但可能下一秒压力是零，如果我们把压力平均一下，每秒处理5千，也许就可以了。

  RPC默认到访问都是同步的，

  所以我们要考虑，流控、限流、使用各种线程，和调用次数等一些限制来保护我们的系统。

  假如我们中间有一个缓冲，其实就不需要了。

  ![远程过程调用](./photos/005远程过程调用.png)

所以说，我们系统之间通信的方式有很多种。每种可能在某些条件下适合，但没有任何一种，可以适应我们所有条件下，所有缓环境下这种系统间的通信方式。

### 2.3 我们期望有一种通信方式

在一些我们对实时性要求比较高，但又没有RPC这么高（RPC要求，1毫秒以内都能访问），比如放宽到2毫秒。并且很多时候，异步也是很重要的（RPC默认是同步的，数据库是异步的，Socket默认是同步的）。所以我们期望又一种通信方式，能够在刚说的条件，特别有要求，限制得特别严格的要求下，还能够很好的支撑我们的业务场景。比如：

- 可以实现异步的消息通信

  能够实现异步的通信能力，我所有的A调用B，B调用E。是异步的调用。这种我们不需要所有的异步调用线程，都在那儿阻塞，等待我们的调用回来再处理。

  这对我们的大事物，或跑批大操作特别有意义。

  比如，我们发起一个任务，这个任务发起完了之后，需要半小时，才跑批跑完。到时候再个我们一个响应（回值）。我们就可以用这样一种东西，来实现我们刚说的，这种通信。

- 